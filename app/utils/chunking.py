"""
文本分块工具模块

该模块提供了将长文本分割成适合向量存储和检索的小块的功能。
使用递归字符文本分割器，确保文本块在语义上保持连贯性。
"""

from langchain_text_splitters import RecursiveCharacterTextSplitter


def chunk_texts(text: str) -> list[str]:
    """
    将输入文本分割成适合向量存储的块
    
    使用递归字符文本分割器，按照预定义的分隔符顺序进行分割，
    确保每个块的大小适中且保持语义连贯性。
    
    分割策略（针对中英文混合文本优化）：
    1. 首先尝试按双换行符分割（段落级别）
    2. 然后尝试按单换行符分割（行级别）
    3. 接着尝试按中文标点符号分割（中文句子级别：句号、感叹号、问号）
    4. 然后尝试按英文标点符号分割（英文句子级别）
    5. 接着尝试按空格分割（单词级别）
    6. 最后按字符分割（字符级别）
    
    这种分割策略确保：
    - 中文文本能在合适的句子边界处分割
    - 英文文本能在句子边界处分割
    - 保持语义连贯性，避免在词语中间断开
    
    Args:
        text: 要分割的输入文本
        
    Returns:
        分割后的文本块列表，每个块的大小约为1200字符，
        相邻块之间有150字符的重叠以保持上下文连贯性
        
    Example:
        >>> text = "这是第一段文本。\\n\\n这是第二段文本。"
        >>> chunks = chunk_texts(text)
        >>> print(chunks)
        ['这是第一段文本。', '这是第二段文本。']
    """
    # 创建递归字符文本分割器实例
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,        # 每个文本块的最大字符数
        chunk_overlap=150,     # 相邻块之间的重叠字符数，用于保持上下文
        separators=[
            "\n\n",             # 段落分隔符
            "\n",               # 行分隔符
            "。",               # 中文句号
            "！",               # 中文感叹号
            "？",               # 中文问号
            ".",                # 英文句号
            "！",               # 英文感叹号
            "？",               # 英文问号
            " ",                # 空格
            ""                  # 字符级别
        ],  # 分割优先级顺序：段落 > 行 > 中文句子 > 英文句子 > 单词 > 字符
    )
    
    # 执行文本分割并返回结果
    return splitter.split_text(text)
